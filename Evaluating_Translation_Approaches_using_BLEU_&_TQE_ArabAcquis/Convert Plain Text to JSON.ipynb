{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyMVp0+gVktrjPsX5ES2E8AT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Converting the ArabAcquis Corpus to JSON Format\n","This Colab notebook presents a Python script designed to process a parallel English-Arabic text corpus from the ArabAcquis dataset. It reads line-aligned sentences from separate English and Arabic input files, pairs the corresponding sentences, and then structures this bilingual data into a single, well-formatted JSON output file. This conversion creates an organized and machine-readable dataset, ideal for further Processing tasks.\n","\n","*   **Input files:**   \n","    *   `ac_test_en.txt` (The English text file)\n","    *   `test_en_ref_ar.txt` (The Corresponding Arabic text file)\n","*   **Output file:**  `ArabAcquis_Original.json`"],"metadata":{"id":"kNaBAc7h0lTP"}},{"cell_type":"markdown","source":[],"metadata":{"id":"PNA8CIzxGuyx"}},{"cell_type":"markdown","source":[],"metadata":{"id":"5Z2_TP5OGut6"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LGrsP1320mUY","executionInfo":{"status":"ok","timestamp":1717195860590,"user_tz":-180,"elapsed":30707,"user":{"displayName":"Shahad Research","userId":"16465047292842471480"}},"outputId":"83a7d95b-f803-4228-d133-95947e1824da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/ColabData/ArabAcquis"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X_GzXbkx0mel","executionInfo":{"status":"ok","timestamp":1717195889376,"user_tz":-180,"elapsed":470,"user":{"displayName":"Shahad Research","userId":"16465047292842471480"}},"outputId":"c741d1bf-618a-400d-9e2c-6c54f2c29689"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ColabData/ArabAcquis\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9aGY_R9c0iua"},"outputs":[],"source":["import json\n","\n","def load_parallel_corpus(file_path_en, file_path_ar):\n","    with open(file_path_en, 'r', encoding='utf-8') as file_en, open(file_path_ar, 'r', encoding='utf-8') as file_ar:\n","        lines_en = file_en.readlines()\n","        lines_ar = file_ar.readlines()\n","    return lines_en, lines_ar\n","\n","def convert_to_json(lines_en, lines_ar):\n","    data = []\n","    for en, ar in zip(lines_en, lines_ar):\n","        data.append({'english': en.strip(), 'arabic': ar.strip()})\n","    return data\n","\n","def save_to_json(data, output_file):\n","    with open(output_file, 'w', encoding='utf-8') as file:\n","        json.dump(data, file, ensure_ascii=False, indent=4)\n","\n","def main():\n","    file_path_en = 'ArabAcquis/ac_test_en.txt'  # The path to English text file\n","    file_path_ar = 'ArabAcquis/test_en_ref_ar.txt'  # The path to Arabic text file\n","    output_file = 'ArabAcquis/ArabAcquis_Original.json'  # The desired output file path\n","\n","    lines_en, lines_ar = load_parallel_corpus(file_path_en, file_path_ar)\n","    data = convert_to_json(lines_en, lines_ar)\n","    save_to_json(data, output_file)\n","\n","if __name__ == \"__main__\":\n","    main()\n"]}]}